\section{Background \& History}\label{sec:background}

\subsection{Generative Task as an Analytic Framework}
Software production exists as an organizationally designed feedback loop between production values and implementation \cite{Derniame:1999fk}, and it is possible to understand a system by understanding the purpose for which it was initially designed, the system's \emph{generative task(s)}. In the analysis of systems created for use by artists, this priority yields a dilemma instantly, as analyses that explain a system's affordances with reference to intended purpose must contend with the creative use of technology by artists: a system's intended uses might have little or nothing in common with the way in which the artist finally uses the technology. For this reason, the notion of generative task is best understood as an explanation for a system's affordances, with the caveat that a user can nonetheless work against those affordances to use the system in novel ways. Generative tasks --- informed by the cultural milieu of software development, economic constraints of software production, and the aesthetic proclivities of artists participating in development processes --- constrain software features to enable a limited subset of possible representations and user interactions.

While composers working traditionally may allow intuition to substitute for formally defined principles, a computer demands the composer to think formally about music \cite{Xenakis:1992rq}. Keeping in mind generative task as an analytical framework, it is broadly useful to bifurcate an automated notation system's development into the modeling of music and composition, on the one hand, and the modeling of musical notation, on the other. All systems model both, to greater or lesser degrees, often engaging in the ambiguous or implicit modeling of music and composition while focusing more ostensibly on a model of notation, or focusing on the abstract modeling of music without a considered link to a model of notation. Due to the intimate link between notation and musical ideas, it is impossible for a system that models notation to avoid at least implicitly modeling musical and compositional ideas, and a computational model of music and composition is an inevitable component of every automated notation system, even when it exists as an unspoken set of technological constraints. Generative task explains a given system's balance between computational models of music/composition and notation by assuming a link between intended use and system development.

\subsection{Computational Models of Notation}

Many systems implement detailed models of music explicitly or implicitly, but few of these implement detailed models of notation.\footnote{Computational models of music might entail the representation of higher-level musical entities apparent in the acts of listening and analysis but absent in the symbols of notation themselves, as determined to be creatively exigent. Programming researchers and musical artists have modeled many such extrasymbolic musical entities, such as large-scale form and transition \cite{polansky1991morphological}, \cite{uno1994temporal}, \cite{dobrian1995algorithmic}, \cite{abrams1999higher}, \cite{Yoo1983}, texture \cite{Horenstein:2004kx}, contrapuntal relationships \cite{Boenn:2009oq}, \cite{Acevedo2005}, \cite{Anders:2011kl}, \cite{Balser:1990tg}, \cite{Jones:2000hc}, \cite{uno1994temporal}, \cite{Bell:1995ij}, \cite{farbood2001analysis}, \cite{Cope:2002fv}, \cite{Laurson:2005dz}, \cite{Polansky:2011fu}, \cite{Ebcioglu:1980kl}, harmonic tension and resolution \cite{Melo2003}, \cite{Wiggins1999}, \cite{Foster:1995qa}, melody \cite{Hornel:1993mi}, \cite{Smith:1992pi}, meter \cite{Hamanaka:2005ff}, rhythm \cite{Nauert2007}, \cite{Degazio:1996lh}, \cite{Collins:2003bs}, timbre \cite{Xenakis:1991fu}, \cite{Creasey:1996ye}, \cite{Osaka2004}, temperament \cite{Seymour:2007qo}, \cite{Graf:2006il}, and ornamentation \cite{Ariza:2003zt}, \cite{Chico-Topfer:1998jl}. This work overlaps fruitfully with analysis tasks, and models of listening and cognition can enable novel methods of high-level musical structures and transformations, like dramatic direction, tension, and transition between sections \cite[108]{Collins2009}.} A system that affords a detailed model of music/composition without linking to a sufficiently detailed model of musical notation does not afford automated notation --- sufficiency, however, depends heavily on generative task. For example, if a composer requires an automated notation system to render complex rhythmic ideas that depend typographically on nested tuplets, a system that produces a notation only via a combination of MIDI and quantization must reduce rhythms to a non-hierarchical stream of event times, eliminating the temporally divisive approach of tuplet notation. For many rhythmic applications, though, MIDI suffices. 

Many automated notation systems exist to model musical notation and the act of typographical layout without explicitly affording the computational modeling of music or composition \cite{Smith:1972mw}, \cite{Nienhuys:2003ve}, \cite{Hoos:1998bd}, \cite{hamel1noteability}; many of these systems strongly imply a model of music, such as Gr\'{e}goire for Gregorian chant, Django for guitar tablature, and GOODFEEL for Braille notation \cite{2006}, while feature-rich systems (often oriented toward classical composers) such as Finale, Sibelius, SCORE, Igor, Berlioz, and Nightingale, present themselves as relatively more genre-agnostic software tools. Such a system might go so far as to enable a text-based object-oriented model of notation that automates some aspect of an otherwise point-and-click interface, as in the case of Sibelius's ManuScript scripting language \cite{Technology:qc}. 

Many models of musical notation have been designed created for purposes of corpus-based computational musicology. Formats such as Music21, DARM, SMDL, HumDrum, and MuseData model notation with the generative task of searching through a large amount of data \cite{Selfridge-Field:1997ud}. Commercial notation software developers attempted to establish a data interchange standard for optical score recognition (NIFF) \cite{niff1995niff}; since its release in 2004, MusicXML has become a valid interchange format for over 160 applications and maintains a relatively application-agnostic status, as it was designed with the generative task of acting as an interchange format between variously tasked systems \cite{Good:2001if}. (are Igor and Berlioz commercial?)

Notation representations that underly many of these GUI-based systems often go undescribed as computer representations of notation, in favor of discussions about human-computer interaction. For example, Barker and Cantor developed an early model of music notation that underlies a four-oscilloscope GUI and describe their work entirely in terms of user interaction \cite{cantor1971computer}; likewise, discussions of modern commercial notation systems remain similarly oriented, without much awareness or criticism of the underlying computational models of notation. This results in insufficiently detailed models of notation; systems, for example, that provide models only of mensural notation and enable nonmensural notations only as modified instantiations of notations based on measures.

\subsection{The Development of Hierarchical Object Models of Notation}
Many early models of musical notation were not hierarchical, and Lejaran Hiller, in reflecting on decades of automated notation work, identifies the lack of hierarchical organization as a limitation of early work --- although Nick Collins points out that even Hiller's program PHRASE addresses the hierarchical organization of a score up to the level of a phrase, without moving beyond this mid-level musical structure to concerns of large-scale form \cite[108]{Collins2009}. 

There were several object-oriented music environments by 1990 \cite[139]{Polansky:1990fk}, most created in or inspired by the newly popular Smalltalk-80 programming language; while they facilitated the hierarchical modeling of musical abstractions, they omitted or radically simplified the hierarchical nature of common notation. For example, Glen Krasner (Xerox Systems Science Laboratory) created Machine Tongues VIII, a music system that created an object-oriented model of the score/orchestra distinction inherited from Max Mathews' Music N languages, with a simple linear model of ``partOn'' and ``partOff'' command sequences \cite{Krasner:1991uq}, omitting hierarchical organization entirely when the system produced notational output; although subsequent Machine Tongues systems introduced some hierarchical organization via ``note'' objects that inhabited ``event lists,'' systems did not attempt to model the hierarchical detail of all a traditional score's elements. Like Hiller's PHRASE program, Andreas Mahling's CompAss system organized events hierarchically up to the mid-level ``phrase'' level of musical structure \cite{Mahling:1991qf}. These systems extend Smalltalk-80 with interfaces to the MIDI communications protocol: as extensions of Smalltalk, they enabled the user to arbitrarily extend the system with new objects, creating a detailed and hierarchical model of music, usually flattened into a list of noteOn and noteOff commands to be notated or played back via MIDI interface. 

By 1989, Glendon Diener's Nutation system (written in Objective C for the NeXT computer) modeled both musical and notational structure hierarchically through the use of directed graphs \cite{Diener:1991zr}, \cite{Diener:1991ly}, \cite{Diener:1989ve}.

last section: system motivations
	

Linking our design priorities with those of previous systems by describing perceived deficiencies: evaluative priorities for previous systems: sufficiency instead of comprehensiveness, potentially evaluated by sonic result rather than notation, addressability (in HMSL and JMSL). Reintroduce generative task: late 50s through 80s were motivated locally by generative tasks of specific projects until IRCAM's Patchwork approached a generative task of broadly enabling composers; sufficiency determined by comprehensive task.